{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B — Modeling & Task C — Anomalies\n",
    "\n",
    "Implement model and anomaly detection here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 7) (40, 5) (854, 7) (4307, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', 120)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "DATA_DIR = Path('../dataset')\n",
    "sup = pd.read_csv(DATA_DIR/'suppliers.csv')\n",
    "prod = pd.read_csv(DATA_DIR/'products.csv')\n",
    "prices = pd.read_csv(DATA_DIR/'price_lists.csv', parse_dates=['valid_from','valid_to'])\n",
    "po = pd.read_csv(DATA_DIR/'purchase_orders.csv', parse_dates=['order_date','promised_date'])\n",
    "deliv = pd.read_csv(DATA_DIR/'deliveries.csv', parse_dates=['actual_delivery_date'])\n",
    "po = po.merge(deliv, on='order_id', how='left')\n",
    "print(sup.shape, prod.shape, prices.shape, po.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad45908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: late_delivery\n",
      "0    0.502206\n",
      "1    0.497794\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Ensure datetime types (already parsed on read, but re-assert just in case)\n",
    "po[\"order_date\"] = pd.to_datetime(po[\"order_date\"], errors=\"coerce\")\n",
    "po[\"promised_date\"] = pd.to_datetime(po[\"promised_date\"], errors=\"coerce\")\n",
    "po[\"actual_delivery_date\"] = pd.to_datetime(po[\"actual_delivery_date\"], errors=\"coerce\")\n",
    "\n",
    "# Target: late_delivery = 1 if actual_delivery_date > promised_date\n",
    "po[\"late_delivery\"] = (po[\"actual_delivery_date\"] > po[\"promised_date\"]).astype(int)\n",
    "\n",
    "print(\"Target distribution:\", po[\"late_delivery\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3ae31",
   "metadata": {},
   "source": [
    "### Target Definition  \n",
    "We define the target variable **`late_delivery`** as 1 when the actual delivery date is later than the promised date, and 0 otherwise.  \n",
    "This gives us a clear label for the prediction task and lets us quantify the share of late deliveries in the data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ae6ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit_price currency  unit_price_eur\n",
      "0       11.81      EUR           11.81\n",
      "1       22.43      EUR           22.43\n",
      "2        7.50      EUR            7.50\n",
      "3       10.65      EUR           10.65\n",
      "4        8.11      EUR            8.11\n"
     ]
    }
   ],
   "source": [
    "# Currency normalization\n",
    "USD_TO_EUR = 0.92\n",
    "\n",
    "if \"unit_price\" in po.columns and \"currency\" in po.columns:\n",
    "    po[\"unit_price_eur\"] = po.apply(\n",
    "        lambda x: x[\"unit_price\"] * USD_TO_EUR if x[\"currency\"] == \"USD\" else x[\"unit_price\"], axis=1\n",
    "    )\n",
    "else:\n",
    "    po[\"unit_price_eur\"] = np.nan\n",
    "\n",
    "print(po[[\"unit_price\",\"currency\",\"unit_price_eur\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56161a2",
   "metadata": {},
   "source": [
    "### Currency Normalization  \n",
    "Purchase orders are recorded in both EUR and USD.  \n",
    "To make prices comparable across suppliers and products, we normalize everything to **EUR**, using the assumption from the exercise that **1 USD = 0.92 EUR**.  \n",
    "The new column `unit_price_eur` will be used in modeling and analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e27fea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance_km distance_bucket\n",
      "0          748        500-1499\n",
      "1         1188        500-1499\n",
      "2          857        500-1499\n",
      "3          729        500-1499\n",
      "4          205            <500\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2.3: Distance buckets ===\n",
    "bins = [-1, 500, 1500, 3000, float(\"inf\")]\n",
    "labels = [\"<500\", \"500-1499\", \"1500-2999\", \"3000+\"]\n",
    "\n",
    "if \"distance_km\" in po.columns:\n",
    "    po[\"distance_bucket\"] = pd.cut(po[\"distance_km\"], bins=bins, labels=labels)\n",
    "else:\n",
    "    po[\"distance_bucket\"] = \"Unknown\"\n",
    "\n",
    "print(po[[\"distance_km\",\"distance_bucket\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4bd0e",
   "metadata": {},
   "source": [
    "### Distance Buckets  \n",
    "To better understand and model the effect of shipping distance, we group `distance_km` into four categories:  \n",
    "- <500 km  \n",
    "- 500–1499 km  \n",
    "- 1500–2999 km  \n",
    "- 3000+ km  \n",
    "\n",
    "This feature can highlight patterns in performance across short- vs. long-haul deliveries.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa3f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared model dataset shape: (4307, 10)\n",
      "Numeric/bool cols: ['urgent', 'qty', 'unit_price_eur', 'distance_km']\n",
      "Categorical-like cols: ['ship_mode', 'incoterm', 'payment_terms', 'distance_bucket']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rabbit User\\AppData\\Local\\Temp\\ipykernel_16948\\2895200834.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(s):\n",
      "C:\\Users\\Rabbit User\\AppData\\Local\\Temp\\ipykernel_16948\\2895200834.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(s):\n",
      "C:\\Users\\Rabbit User\\AppData\\Local\\Temp\\ipykernel_16948\\2895200834.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(s):\n",
      "C:\\Users\\Rabbit User\\AppData\\Local\\Temp\\ipykernel_16948\\2895200834.py:31: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(s):\n"
     ]
    }
   ],
   "source": [
    "#  Select order-time features & robust imputation \n",
    "from pandas.api.types import is_numeric_dtype, is_bool_dtype, is_categorical_dtype\n",
    "\n",
    "feature_cols = [\n",
    "    \"supplier_rating\", \"preferred_supplier\", \"country\", \"ship_mode\", \"incoterm\",\n",
    "    \"payment_terms\", \"hazardous_flag\", \"promised_lead_days\", \"urgent\",\n",
    "    \"qty\", \"unit_price_eur\", \"distance_km\", \"distance_bucket\"\n",
    "]\n",
    "\n",
    "use_cols = [c for c in feature_cols if c in po.columns]\n",
    "df_model = po[use_cols + [\"late_delivery\",\"order_date\"]].copy()\n",
    "\n",
    "# Split columns by dtype in a robust way\n",
    "numeric_or_bool = []\n",
    "categorical_like = []\n",
    "for c in use_cols:\n",
    "    s = df_model[c]\n",
    "    if is_numeric_dtype(s) or is_bool_dtype(s):\n",
    "        numeric_or_bool.append(c)\n",
    "    else:\n",
    "        categorical_like.append(c)\n",
    "\n",
    "# Impute numeric/bool with median (bools will be treated as 0/1 if missing occurs)\n",
    "for c in numeric_or_bool:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\")  # ensure numeric\n",
    "    df_model[c] = df_model[c].fillna(df_model[c].median())\n",
    "\n",
    "# Impute categoricals safely (handle true pandas.Categorical and plain object)\n",
    "for c in categorical_like:\n",
    "    s = df_model[c]\n",
    "    if is_categorical_dtype(s):\n",
    "        # add \"Unknown\" to categories, then fill\n",
    "        df_model[c] = s.cat.add_categories([\"Unknown\"]).fillna(\"Unknown\")\n",
    "    else:\n",
    "        # make sure it's object/string, then fill\n",
    "        df_model[c] = s.astype(\"object\").fillna(\"Unknown\")\n",
    "\n",
    "# Clean target\n",
    "df_model[\"late_delivery\"] = df_model[\"late_delivery\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Prepared model dataset shape:\", df_model.shape)\n",
    "print(\"Numeric/bool cols:\", numeric_or_bool)\n",
    "print(\"Categorical-like cols:\", categorical_like)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b022d86",
   "metadata": {},
   "source": [
    "### Order-Time Features and Missing Values  \n",
    "For modeling, we only keep information that is **available at the time of order** (e.g. supplier attributes, promised lead days, unit price, ship mode).  \n",
    "We exclude any data that would only be known after delivery to avoid leakage.  \n",
    "\n",
    "Missing values are handled as follows:  \n",
    "- **Numeric fields** (e.g. lead days, unit price) → imputed with the median.  \n",
    "- **Categorical fields** (e.g. ship mode, payment terms) → imputed with `\"Unknown\"`.  \n",
    "\n",
    "This ensures the dataset is consistent and ready for model training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83544496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3572, 8) Valid: (735, 8)\n",
      "Late rate — Train: 0.49384098544232924 | Valid: 0.5170068027210885\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2.5: Temporal split ===\n",
    "df_model[\"order_date\"] = pd.to_datetime(df_model[\"order_date\"], errors=\"coerce\")\n",
    "\n",
    "train_df = df_model[df_model[\"order_date\"] <= \"2025-03-31\"].copy()\n",
    "valid_df = df_model[(df_model[\"order_date\"] >= \"2025-04-01\") & (df_model[\"order_date\"] <= \"2025-06-30\")].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"late_delivery\",\"order_date\"])\n",
    "y_train = train_df[\"late_delivery\"]\n",
    "X_valid = valid_df.drop(columns=[\"late_delivery\",\"order_date\"])\n",
    "y_valid = valid_df[\"late_delivery\"]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Valid:\", X_valid.shape)\n",
    "print(\"Late rate — Train:\", y_train.mean(), \"| Valid:\", y_valid.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02b6e3",
   "metadata": {},
   "source": [
    "### Train/Validation Split  \n",
    "We split the data on **order date** to mimic real-world prediction:  \n",
    "- **Training set** → all orders up to 31 March 2025  \n",
    "- **Validation set** → orders from 1 April to 30 June 2025  \n",
    "\n",
    "This prevents future information from leaking into training and gives a realistic test of model performance on new data.  \n",
    "We also check the late-delivery rate in each set to confirm that the split is representative.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dcb382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC: 0.6100058817290945\n",
      "ROC-AUC: 0.6074796145292809\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score\n",
    "\n",
    "# --- original skeleton ---\n",
    "df = po.query('cancelled == 0').copy()\n",
    "df['late_delivery'] = df['late_delivery'].fillna(0).astype(int)\n",
    "cutoff = pd.Timestamp('2025-03-31')\n",
    "train = df[df['order_date'] <= cutoff].copy()\n",
    "valid = df[df['order_date'] > cutoff].copy()\n",
    "\n",
    "def engineer(d):\n",
    "    out = d.copy()\n",
    "    out['promised_lead_days'] = (out['promised_date'] - out['order_date']).dt.days\n",
    "    out['month'] = out['order_date'].dt.month\n",
    "    out = out.merge(sup[['supplier_id','preferred','rating']], on='supplier_id', how='left')\n",
    "    out = out.merge(prod[['sku','hazard_class']], on='sku', how='left')\n",
    "    out['is_hazard'] = (out['hazard_class']!='none').astype(int)\n",
    "    out['is_eur'] = (out['currency']=='EUR').astype(int)\n",
    "    out = pd.get_dummies(out, columns=['ship_mode','incoterm','payment_terms'], drop_first=True)\n",
    "    return out\n",
    "\n",
    "X_train = engineer(train); X_valid = engineer(valid)\n",
    "y_train = X_train['late_delivery']; y_valid = X_valid['late_delivery']\n",
    "cols_drop = [\n",
    "    'order_id','order_date','promised_date','actual_delivery_date',\n",
    "    'order_notes','sku','currency','hazard_class','late_delivery',\n",
    "    'delay_days','partial_delivery','delay_reason'\n",
    "]\n",
    "X_train = X_train.drop(columns=cols_drop, errors='ignore')\n",
    "X_valid = X_valid.drop(columns=cols_drop, errors='ignore')\n",
    "\n",
    "# --- minimal fix: ensure purely numeric features & aligned columns ---\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def make_numeric(Xtr, Xva):\n",
    "    Xtr = Xtr.copy(); Xva = Xva.copy()\n",
    "\n",
    "    # 1) booleans -> ints\n",
    "    for df_ in (Xtr, Xva):\n",
    "        for c in df_.select_dtypes(include='bool').columns:\n",
    "            df_[c] = df_[c].astype(int)\n",
    "\n",
    "    # 2) one-hot ANY remaining object/category columns on combined frame (keeps schema consistent)\n",
    "    obj_cols = list(set(Xtr.select_dtypes(include=['object','category']).columns) |\n",
    "                    set(Xva.select_dtypes(include=['object','category']).columns))\n",
    "    if obj_cols:\n",
    "        both = pd.concat([Xtr[obj_cols], Xva[obj_cols]], axis=0, ignore_index=True)\n",
    "        dummies = pd.get_dummies(both, drop_first=True)\n",
    "        d_tr = dummies.iloc[:len(Xtr)].set_index(Xtr.index)\n",
    "        d_va = dummies.iloc[len(Xtr):].set_index(Xva.index)\n",
    "        Xtr = pd.concat([Xtr.drop(columns=obj_cols), d_tr], axis=1)\n",
    "        Xva = pd.concat([Xva.drop(columns=obj_cols), d_va], axis=1)\n",
    "\n",
    "    # 3) coerce to numeric & impute train medians; apply same medians to valid\n",
    "    Xtr = Xtr.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    med = Xtr.median()\n",
    "    Xtr = Xtr.fillna(med)\n",
    "    Xva = Xva.apply(pd.to_numeric, errors=\"coerce\").fillna(med)\n",
    "\n",
    "    # 4) align columns\n",
    "    Xva = Xva.reindex(columns=Xtr.columns, fill_value=0)\n",
    "    return Xtr, Xva\n",
    "\n",
    "X_train_num, X_valid_num = make_numeric(X_train, X_valid)\n",
    "\n",
    "# --- fit & metrics (unchanged API) ---\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=0, class_weight='balanced')\n",
    "clf.fit(X_train_num, y_train)\n",
    "p_valid = clf.predict_proba(X_valid_num)[:,1]\n",
    "print('PR-AUC:', average_precision_score(y_valid, p_valid))\n",
    "print('ROC-AUC:', roc_auc_score(y_valid, p_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27ffd581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late_delivery\n",
      "1    380\n",
      "0    355\n",
      "Name: count, dtype: int64\n",
      "Overlap count: 0\n",
      "Suspicious columns: ['delay_days', 'partial_delivery', 'delay_reason']\n",
      "Perfect predictors: [('delay_days', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "# 1. Make sure y_valid actually has both 0s and 1s\n",
    "print(y_valid.value_counts())\n",
    "\n",
    "# 2. Check if there’s overlap in order_id\n",
    "overlap = set(train['order_id']).intersection(set(valid['order_id']))\n",
    "print('Overlap count:', len(overlap))\n",
    "\n",
    "# 3. Look for suspicious feature names\n",
    "import re\n",
    "suspects = [c for c in X_train.columns if re.search(r'(actual|deliv|delay|late)', c, re.I)]\n",
    "print('Suspicious columns:', suspects)\n",
    "\n",
    "# 4. Check if any single feature perfectly predicts the target\n",
    "from sklearn.metrics import roc_auc_score\n",
    "perfect = []\n",
    "for c in X_train.columns:\n",
    "    try:\n",
    "        auc = roc_auc_score(y_valid, X_valid[c].fillna(0))\n",
    "        if auc in (0.0, 1.0):\n",
    "            perfect.append((c, auc))\n",
    "    except:\n",
    "        pass\n",
    "print('Perfect predictors:', perfect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prices_ = prices.copy()\n",
    "prices_['price_eur'] = np.where(prices_['currency']=='EUR', prices_['price_per_uom'], prices_['price_per_uom']/1.09)\n",
    "results = []\n",
    "for (sid, sku), g in prices_.groupby(['supplier_id','sku']):\n",
    "    g = g.sort_values('valid_from').copy()\n",
    "    x = np.log1p(g['price_eur'])\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med)) or 1e-6\n",
    "    z = 0.6745*(x - med)/mad\n",
    "    g['robust_z'] = z\n",
    "    top = g.loc[g['robust_z'].abs().sort_values(ascending=False).head(3).index]\n",
    "    for _, r in top.iterrows():\n",
    "        results.append({'supplier_id': sid, 'sku': sku, 'valid_from': r['valid_from'], 'price_eur': r['price_eur'], 'robust_z': r['robust_z']})\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).sort_values('robust_z', key=lambda s: s.abs(), ascending=False).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
